# 国内成品油社会单位成交价数据清洗需求文档


## 一、需求背景
对国内成品油社会单位的主流成交价数据进行标准化清洗，解决数据格式不统一、存在重复值、异常值等问题，输出便于分析的结构化数据，支撑供应链数据分析需求。


## 二、输入数据说明
1. **数据源**：多个Excel文件，存储路径为`/Users/didi/Downloads/panth/gyl/yk`，文件内包含多个工作表，表结构一致但表名不同。
2. **核心字段**：
   - 固定字段：地区、厂家、品类、涨跌金额、涨跌幅度、备注。
   - 变动字段：每日成交价列（如“7月30日”“7月29日”，字段名随日期更新）。
3. **特殊格式**：存在合并单元格，表头可能不在第一行。


## 三、数据清洗规则
### （一）字段映射与格式转换
1. **date**：提取变动日期字段（如“7月30日”“7月29日”），取其中最大日期，转换为`yyyy-mm-dd`格式。
2. **oil_depot_name**：对应“厂家”字段。
3. **oil_92_price**：在“品类”中匹配“92#”，取最大日期列的价格值。
4. **oil_95_price**：在“品类”中匹配“95#”，取最大日期列的价格值。
5. **oil_0_price**：在“品类”中匹配“0#”，取最大日期列的价格值。
6. **oil_92_rise_fall_range**：在“品类”中匹配“92#”，对应“涨跌幅度”列的值。
7. **region**：对应“地区”字段。
8. **异常值处理**：非数字可读的值统一赋值为`null`，“控制”（如停付、无货）状态保留原值。


### （二）数据去重与索引规则
1. **唯一索引**：以`date + oil_depot_name`作为唯一标识。
2. **去重逻辑**：若存在重复记录（同一日期同一厂家），按`oil_92_price`降序排序，保留第一条记录（即价格最高的记录），不保留原始重复数据。


### （三）防呆校验规则
1. **新增均值字段**：为3个价格字段新增7天均值校验字段：
   - `oil_92_price_week`：对应`oil_92_price`的过去7天有效数据均值；
   - `oil_95_price_week`：对应`oil_95_price`的过去7天有效数据均值；
   - `oil_0_price_week`：对应`oil_0_price`的过去7天有效数据均值。
2. **异常标记**：若当天价格与对应7天均值偏离超过±20%（即`|(当天值-均值)/均值| > 20%`），标记为异常；“控制”状态或无数据不视为异常。


### （四）排序规则
1. **一级排序**：按`date`降序（最新日期在前）。
2. **二级排序**：按`oil_depot_name`（厂家）的固定顺序排列：
   - 固定列表：沈阳乐天、蓝天优源、上海海航能源、浙江东海长城、江苏锡通石油、湖北兴储石化、湖南和顺石油、北京中油晟德、河南恒润筑邦、河北开滦油库、山西延长中化、内蒙古广厦石油、广西永盛石化、福建闽海石化、广东国油能源、广东海科石化、四川中航油油库、贵州国储、云南强林石化。
   - 不在固定列表中的厂家，按名称升序排列在固定列表之后。


## 四、输出要求
1. **文件存储**：保存至指定路径`/Users/didi/Downloads/panth/gyl/`。
2. **文件命名**：格式为“社会单位主流油库价清洗+时分级时间戳”（如“社会单位主流油库价清洗202507311530.xlsx”）。
3. **数据合并**：一次性遍历所有输入文件的工作表，将清洗后的数据合并为一个文件输出。


## 五、补充说明
- 输入文件中日期可能以中文格式（如“7月30日”）或Excel序列号（如“45856”）存在，需统一识别转换。
- 合并单元格需通过前向填充处理，确保数据完整性。


1.主流社会单位/油库数据
数据源，/Users/didi/Downloads/panth/gyl/yk，
里面有多个表，但表结构都一致，表名不一样。

字段/地区/厂家/	品类	/7月30日	/7月29日/	涨跌金额	/涨跌幅度	/备注
有合并单元格，字段可能不在第一行。
固定名称：
字段/地区/厂家/	品类/	涨跌金额	/涨跌幅度	/备注
变动名称：
	/7月30日	/7月29日，是每天数据更新的日期


清洗成

date/	oil_depot_name/	oil_92_price	/oil_95_price	/oil_0_price	/oil_92_rise_fall_range

date 等于 变动名称：
	/7月30日	/7月29日，比较2个日期中的最大的1个。名称是中文格式
转写成yyyy-dd-mm，

下面的数据，我举例用7月30日的例子

oil_depot_name 等于 厂家
oil_92_price	等于 品类中查找92# 匹配7月30日 列的值
oil_95_price	等于 品类中查找95# 匹配7月30日 列的值
oil_0_price	等于 品类中查找0# 匹配7月30日 列的值
oil_92_rise_fall_range 等于 品类中查找92# 匹配  涨跌幅度 列的值
地区 等于地区

按date 降序 排序
异常值处理，非数字可读，全部赋值为null


输出要求：
1.保存到这个里，/Users/didi/Downloads/panth/gyl/
2.文件名称按社会单位主流油库价清洗+时间戳（时分级）
3.一次性历遍文件中全部表格，产出到一个文件中。

把我这个清洗要求总结成一个需求模板，字段和输出输入文件夹可变。

仔细确认需求，评估方案，需要我的输入分配为我的todo，给出你的计划方案。跟我交互拉齐，待我完全确认后，我将回复“确认，请开始”，你在开始将需求转化为具体的代码编写。



import os
import re
import pandas as pd
import numpy as np
from datetime import datetime, timedelta
import glob

def find_header_row(df):
    """寻找包含关键表头的行"""
    for i, row in df.iterrows():
        row_str = ' '.join([str(x).lower() for x in row if pd.notna(x)])
        if '地区' in row_str and '厂家' in row_str and '品类' in row_str:
            return i
    return 0  # 如果没找到，默认第一行为表头

def parse_chinese_date(date_str):
    """将中文日期如'7月30日'转换为datetime对象"""
    try:
        # 假设年份是当前年份，可根据实际情况调整
        year = datetime.now().year
        month, day = re.findall(r'(\d+)月(\d+)日', date_str)[0]
        return datetime(int(year), int(month), int(day))
    except:
        return None

def convert_to_standard_date(date_str):
    """将中文日期转换为yyyy-dd-mm格式"""
    dt = parse_chinese_date(date_str)
    if dt:
        return dt.strftime('%Y-%d-%m')
    return None

def is_numeric(value):
    """判断值是否为数字"""
    try:
        float(value)
        return True
    except:
        return False

def process_worksheet(df, sheet_name):
    """处理单个工作表"""
    # 寻找表头行
    header_row = find_header_row(df)
    
    # 重新设置表头
    new_header = df.iloc[header_row]
    df = df.iloc[header_row+1:]
    df.columns = new_header
    
    # 处理合并单元格（这里简单处理，实际可能需要更复杂的逻辑）
    df = df.fillna(method='ffill')
    
    # 获取所有列名
    columns = df.columns.tolist()
    
    # 识别日期列（变动名称列）
    date_columns = []
    date_pattern = re.compile(r'\d+月\d+日')
    for col in columns:
        if date_pattern.match(str(col)):
            date_columns.append(col)
    
    if not date_columns:
        print(f"工作表 {sheet_name} 未找到日期列，跳过处理")
        return pd.DataFrame()
    
    # 找到最大的日期列
    date_objs = {col: parse_chinese_date(col) for col in date_columns}
    max_date_col = max(date_columns, key=lambda x: date_objs[x])
    max_date = convert_to_standard_date(max_date_col)
    
    # 提取需要的列
    required_cols = ['地区', '厂家', '品类', '涨跌幅度']
    missing_cols = [col for col in required_cols if col not in columns]
    if missing_cols:
        print(f"工作表 {sheet_name} 缺少必要列: {missing_cols}，跳过处理")
        return pd.DataFrame()
    
    # 按厂家分组处理
    results = []
    for factory in df['厂家'].unique():
        factory_data = df[df['厂家'] == factory]
        
        # 提取地区（假设一个厂家对应一个地区）
        region = factory_data['地区'].iloc[0] if not factory_data['地区'].empty else None
        
        # 查找各类油品数据
        oil_92_price = None
        oil_95_price = None
        oil_0_price = None
        oil_92_rise_fall = None
        
        for _, row in factory_data.iterrows():
            category = str(row['品类']).strip()
            
            # 处理价格
            price = row[max_date_col] if max_date_col in row else None
            if not is_numeric(price):
                price = None
            
            # 处理涨跌幅度
            rise_fall = row['涨跌幅度'] if '涨跌幅度' in row else None
            if not is_numeric(rise_fall):
                rise_fall = None
            
            if '92#' in category:
                oil_92_price = price
                oil_92_rise_fall = rise_fall
            elif '95#' in category:
                oil_95_price = price
            elif '0#' in category:
                oil_0_price = price
        
        # 添加到结果，按指定顺序排列字段
        results.append({
            'date': max_date,
            'oil_depot_name': factory,
            'oil_92_price': oil_92_price,
            'oil_95_price': oil_95_price,
            'oil_0_price': oil_0_price,
            'oil_92_rise_fall_range': oil_92_rise_fall,
            'region': region  # 调整到最后
        })
    
    return pd.DataFrame(results)

def process_all_files(input_dir, output_dir):
    """处理所有文件"""
    # 获取所有Excel文件
    excel_files = glob.glob(os.path.join(input_dir, '*.xlsx')) + glob.glob(os.path.join(input_dir, '*.xls'))
    
    if not excel_files:
        print(f"在 {input_dir} 未找到Excel文件")
        return
    
    all_data = []
    
    # 遍历所有文件
    for file in excel_files:
        print(f"处理文件: {file}")
        try:
            # 获取所有工作表
            excel = pd.ExcelFile(file)
            sheets = excel.sheet_names
            
            # 遍历所有工作表
            for sheet in sheets:
                print(f"  处理工作表: {sheet}")
                df = pd.read_excel(file, sheet_name=sheet, header=None)
                processed = process_worksheet(df, sheet)
                if not processed.empty:
                    all_data.append(processed)
        except Exception as e:
            print(f"处理文件 {file} 时出错: {str(e)}")
            continue
    
    if not all_data:
        print("没有处理到任何有效数据")
        return
    
    # 合并所有数据
    final_df = pd.concat(all_data, ignore_index=True)
    
    # 按date降序排序
    final_df['date'] = pd.to_datetime(final_df['date'], format='%Y-%d-%m')
    final_df = final_df.sort_values('date', ascending=False)
    final_df['date'] = final_df['date'].dt.strftime('%Y-%d-%m')
    
    # 异常值处理 - 确保非数字值为null
    numeric_cols = ['oil_92_price', 'oil_95_price', 'oil_0_price', 'oil_92_rise_fall_range']
    for col in numeric_cols:
        final_df[col] = pd.to_numeric(final_df[col], errors='coerce')
    
    # 生成输出文件名（时分级时间戳）
    timestamp = datetime.now().strftime('%Y%m%d%H%M')
    output_filename = f"社会单位主流油库价清洗{timestamp}.xlsx"
    output_path = os.path.join(output_dir, output_filename)
    
    # 保存结果
    final_df.to_excel(output_path, index=False)
    print(f"清洗完成，结果保存至: {output_path}")

if __name__ == "__main__":
    # 输入文件夹路径（按你的要求设置）
    input_directory = "/Users/didi/Downloads/panth/gyl/yk"
    
    # 输出文件夹路径（按你的要求设置）
    output_directory = "/Users/didi/Downloads/panth/gyl/"
    
    # 确保输出文件夹存在
    os.makedirs(output_directory, exist_ok=True)
    
    # 执行处理
    process_all_files(input_directory, output_directory)