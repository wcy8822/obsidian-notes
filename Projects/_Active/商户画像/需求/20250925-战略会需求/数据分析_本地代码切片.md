
# 阈值的科学定位

---

# 商户画像_战略会_数据分析需求.md

可以的！你只要把**数据长什么样**、**在哪儿**、**怎么连**这三件事说清，我就能给你一套可本地跑的 parser+分析脚本。先给你一个“我需要你提供的信息清单”，再附一份**可配置的 starter 方案**（`config.yaml + main.py`）。你把清单里的信息回给我，我就能把代码按你的口径填好；或者你直接改配置就能跑。

## 你需要提供的信息（一次到位）

1. **文件路径与命名**

   * `transactions_day.csv` 路径（交易按站聚合的当日快照）
   * `tags_day.csv` 路径（标签当日快照）
   * 如果合同费率不在标签表，请给 `contracts_day.csv` 路径，或让交易表/标签表里自带 `rate_contract`
2. **字段与数据类型**（两表最少需要）

   * 交易：`station_id(str), brand(str), province(str), city(str), orders(int), gmv(float), rate_actual(float), profit_per_order(float,可选)`
   * 标签：`station_id(str), overlap(int in {0,1,99}), brand_level(str in {KA, CKA, 小散, 99}), rate_contract(float, 可选), evidence_state(str, 可选)`
3. **分隔符/编码/缺失值**

   * 例：逗号分隔、UTF-8、缺失值用空字符串或 `NA/Null`；小数点是`.`
4. **主键与关联关系**

   * 以 `station_id` 左连接：`transactions_day` × `tags_day`
5. **时间口径**

   * 自然日 T+1 的哪天（用于输出命名）
6. **阈值偏好**（不填就用默认）

   * 重叠绿灯阈：Δ费率 **30bp**；品牌绿灯阈：**50bp**；最小样本 **N=30**
   * 回收率三档：**30/50/70%**（默认 P50=50% 作为保守列）
7. **地域选取策略**

   * Top 省区数量（默认8）、Top 城市数量（默认5）
   * 选取口径：`gmv`（规模）或 `uplift_conservative`（机会），默认 `gmv`
8. **未知值/覆盖率**

   * `overlap=99`、`brand_level=99` 视为未知，只用于覆盖率，不进主结论
9. **单位与精度**

   * 费率单位是百分数（如 6.1 表示 6.1% 还是 0.061？）——默认按**百分数**处理（6.1%→6.1）
10. **输出目录**

* 写入结果 CSV 的目录（默认 `./out`）

---

## Starter 配置（你本地可直接用）

**config.yaml（示例）**

```yaml
run_date: "2025-09-16"        # 当日T+1对应日期
paths:
  transactions_csv: "./data/transactions_day.csv"
  tags_csv: "./data/tags_day.csv"
  out_dir: "./out"
io:
  sep: ","                     # 分隔符
  encoding: "utf-8"
  na_values: ["", "NA", "NULL", "NaN"]
schema:
  transactions:
    station_id: string
    brand: string
    province: string
    city: string
    orders: int64
    gmv: float64
    rate_actual: float64
    profit_per_order: float64?   # 可选
  tags:
    station_id: string
    overlap: int64               # 0/1/99
    brand_level: string          # KA/CKA/小散/99
    rate_contract: float64?      # 可选
    evidence_state: string?
params:
  rate_unit: "percent"           # "percent" 或 "fraction"
  thresholds:
    min_sample_main: 30
    min_sample_display: 10
    overlap_green_bp: 30
    brand_green_bp: 50
  recovery_rates: [0.3, 0.5, 0.7]
selection:
  top_provinces_n: 8
  top_cities_n: 5
  top_mode: "gmv"                # "gmv" 或 "uplift"
```

**main.py（精简可跑版，Pandas 实现）**

> 说明：统一用 **P50/P25/P75** 做质量值，`ΔP50` 做对照差；计算 `uplift_benchmark` 与 `uplift_contract`（30/50/70%），并给保守列 `min(benchmark, contract@50%)`。输出四个结果：`basic_overview.csv`、`opportunities_overlap.csv`、`opportunities_brand.csv`、`top_opportunities.csv`。

```python
import argparse, os, math, warnings, yaml
import pandas as pd
import numpy as np

warnings.filterwarnings("ignore")

def q(df, col, p): return df[col].quantile(p, interpolation="linear")
def pct_to_float(x, rate_unit):
    if pd.isna(x): return np.nan
    return float(x)/100.0 if rate_unit=="percent_fraction" else float(x)

def load_cfg(path):
    with open(path, "r", encoding="utf-8") as f:
        return yaml.safe_load(f)

def load_csv(path, schema, io):
    dtypes={}
    for k,v in schema.items():
        base=v.replace("?","")
        if base in ["string"]: dtypes[k]="string"
        elif base in ["int64"]: dtypes[k]="Int64"
        elif base in ["float64"]: dtypes[k]="float64"
    return pd.read_csv(path, sep=io["sep"], encoding=io["encoding"],
                       dtype=dtypes, na_values=io["na_values"])

def prepare(cfg):
    t=load_csv(cfg["paths"]["transactions_csv"], cfg["schema"]["transactions"], cfg["io"])
    g=load_csv(cfg["paths"]["tags_csv"], cfg["schema"]["tags"], cfg["io"])

    # 合并
    df = t.merge(g, on="station_id", how="left", validate="m:1")

    # 费率单位处理（默认视为百分数：6.1 => 6.1）
    # 如果你存的是 0.061，请把 rate_unit 改成 "fraction" 并删除以下两行
    # 这里保持不变，只确保数值型
    for col in ["rate_actual","rate_contract"]:
        if col in df.columns: df[col] = pd.to_numeric(df[col], errors="coerce")

    # 计算 fee_gap
    if "rate_contract" in df.columns:
        df["fee_gap"] = df["rate_contract"] - df["rate_actual"]
    else:
        df["fee_gap"] = np.nan

    # 标准化未知
    df["overlap"] = df["overlap"].fillna(99)
    df["brand_level"] = df["brand_level"].fillna("99")

    # 基本字段
    need = ["station_id","brand","province","city","orders","gmv",
            "rate_actual","fee_gap","overlap","brand_level"]
    for c in need:
        if c not in df.columns:
            raise ValueError(f"缺字段: {c}")
    return df

def group_quantiles(df, by, value_cols):
    out = df.groupby(by).agg(
        **{f"{c}_p50": (c, lambda s: s.quantile(0.5)) for c in value_cols},
        **{f"{c}_p25": (c, lambda s: s.quantile(0.25)) for c in value_cols},
        **{f"{c}_p75": (c, lambda s: s.quantile(0.75)) for c in value_cols},
        n=("station_id","count"),
        orders_sum=("orders","sum"),
        gmv_sum=("gmv","sum"))
    out = out.reset_index()
    return out

def basic_overview(df):
    # 重叠与品牌两个视角
    cols=["rate_actual","fee_gap"]
    overlap_view = group_quantiles(df, ["province","city","overlap"], cols)
    brand_view   = group_quantiles(df, ["province","city","brand_level"], cols)
    return overlap_view, brand_view

def overlap_opps(df, min_display=10):
    # 同城×同品牌：overlap=0 vs 1 的 P50 差
    grp = df[df["overlap"].isin([0,1])].groupby(["city","brand","overlap"]).agg(
        rate_p50=("rate_actual", lambda s: s.quantile(0.5)),
        fee_gap_p50=("fee_gap", lambda s: s.quantile(0.5)),
        n=("station_id","count"),
        gmv=("gmv","sum")
    ).reset_index()
    a = grp[grp["overlap"]==0].rename(columns={"rate_p50":"p50_o0","n":"n0","gmv":"gmv0","fee_gap_p50":"gap0"})
    b = grp[grp["overlap"]==1].rename(columns={"rate_p50":"p50_o1","n":"n1","gmv":"gmv1","fee_gap_p50":"gap1"})
    m = pd.merge(a,b,on=["city","brand"])
    m["delta_p50"] = m["p50_o0"] - m["p50_o1"]
    m["n_pair"]    = m[["n0","n1"]].min(axis=1)
    m["gmv_base"]  = m["gmv1"]  # 以有重叠作为上拉对象
    m["fee_gap_p50"]= m["gap1"] # 以有重叠组的中位gap计算合同回收
    m = m[m["n_pair"]>=min_display]
    return m[["city","brand","delta_p50","n_pair","gmv_base","fee_gap_p50"]]

def brand_opps(df, min_display=10):
    # 同城：KA/CKA/小散 的 P50；下拉形成相邻档差
    grp = df[df["brand_level"].isin(["KA","CKA","小散"])].groupby(["city","brand_level"]).agg(
        p50=("rate_actual", lambda s: s.quantile(0.5)),
        fee_gap_p50=("fee_gap", lambda s: s.quantile(0.5)),
        n=("station_id","count"),
        gmv=("gmv","sum")
    ).reset_index()
    piv = grp.pivot(index="city", columns="brand_level", values="p50")
    gmv = grp.pivot(index="city", columns="brand_level", values="gmv")
    gap = grp.pivot(index="city", columns="brand_level", values="fee_gap_p50")

    rows=[]
    for city in piv.index:
        # CKA→KA
        if "CKA" in piv.columns and "KA" in piv.columns:
            d = (piv.at[city,"KA"] - piv.at[city,"CKA"])
            n_ck = int(grp[(grp.city==city)&(grp.brand_level=="CKA")]["n"].sum())
            gmv_ck= float(gmv.at[city,"CKA"]) if "CKA" in gmv.columns else np.nan
            gap_ck= float(gap.at[city,"CKA"]) if "CKA" in gap.columns else np.nan
            if n_ck>=min_display:
                rows.append([city,"CKA→KA",d,n_ck,gmv_ck,gap_ck])
        # 小散→CKA
        if "小散" in piv.columns and "CKA" in piv.columns:
            d = (piv.at[city,"CKA"] - piv.at[city,"小散"])
            n_ss = int(grp[(grp.city==city)&(grp.brand_level=="小散")]["n"].sum())
            gmv_ss= float(gmv.at[city,"小散"]) if "小散" in gmv.columns else np.nan
            gap_ss= float(gap.at[city,"小散"]) if "小散" in gap.columns else np.nan
            if n_ss>=min_display:
                rows.append([city,"小散→CKA",d,n_ss,gmv_ss,gap_ss])
    out = pd.DataFrame(rows, columns=["city","ladder","delta_p50","n","gmv_base","fee_gap_p50"])
    return out

def add_uplift(df, recovery=[0.3,0.5,0.7]):
    df["uplift_benchmark"] = df["delta_p50"] * df["gmv_base"]
    for r in recovery:
        df[f"uplift_contract_p{int(r*100)}"] = df["fee_gap_p50"].clip(lower=0).fillna(0) * df["gmv_base"] * r
    df["uplift_conservative"] = np.minimum(df["uplift_benchmark"], df["uplift_contract_p50"])
    return df

def color_flag(df, kind, green_bp, min_sample):
    if kind=="overlap": th=green_bp
    else: th=green_bp # 品牌可在外层传 50
    def flag(row):
        if row["n"] if "n" in row else row["n_pair"] < min_sample: return "RED"
        return "GREEN" if (row["delta_p50"]*100)>=th else ("YELLOW" if (row["delta_p50"]*100)>=th*0.333 else "RED")
    return df.assign(flag=df.apply(flag, axis=1))

def select_regions(df_overview, cfg):
    # 取 Top 省、Top 城（默认按 GMV）
    key = "gmv_sum"
    prov = df_overview.groupby("province", as_index=False)[key].sum().sort_values(key, ascending=False)
    top_prov = prov.head(cfg["selection"]["top_provinces_n"])["province"].tolist()
    city = df_overview.groupby(["province","city"], as_index=False)[key].sum()
    top_city = (city[city["province"].isin(top_prov)]
                .sort_values(key, ascending=False)
                .groupby("province").head(cfg["selection"]["top_cities_n"]))
    return top_prov, top_city["city"].unique().tolist()

def main(cfg_path):
    cfg = load_cfg(cfg_path)
    os.makedirs(cfg["paths"]["out_dir"], exist_ok=True)
    df = prepare(cfg)

    # 基本面
    overlap_view, brand_view = basic_overview(df)
    overlap_view.to_csv(os.path.join(cfg["paths"]["out_dir"], "basic_overview_overlap.csv"), index=False, encoding="utf-8")
    brand_view.to_csv(os.path.join(cfg["paths"]["out_dir"], "basic_overview_brand.csv"), index=False, encoding="utf-8")

    # 机会：重叠
    opp_o = overlap_opps(df, cfg["params"]["thresholds"]["min_sample_display"])
    opp_o = add_uplift(opp_o, cfg["params"]["recovery_rates"])
    opp_o["n"] = opp_o["n_pair"]
    opp_o = color_flag(opp_o, "overlap",
                       cfg["params"]["thresholds"]["overlap_green_bp"],
                       cfg["params"]["thresholds"]["min_sample_main"])
    opp_o.to_csv(os.path.join(cfg["paths"]["out_dir"], "opportunities_overlap.csv"), index=False, encoding="utf-8")

    # 机会：品牌
    opp_b = brand_opps(df, cfg["params"]["thresholds"]["min_sample_display"])
    opp_b = add_uplift(opp_b, cfg["params"]["recovery_rates"])
    opp_b = color_flag(opp_b, "brand",
                       cfg["params"]["thresholds"]["brand_green_bp"],
                       cfg["params"]["thresholds"]["min_sample_main"])
    opp_b.to_csv(os.path.join(cfg["paths"]["out_dir"], "opportunities_brand.csv"), index=False, encoding="utf-8")

    # Top 清单（合并两条腿）
    opp_b = opp_b.rename(columns={"city":"city","ladder":"brand_ladder"})
    opp_o["brand_ladder"] = ""
    opp_b["brand"] = ""
    common_cols = ["city","brand","brand_ladder","delta_p50","n","gmv_base","fee_gap_p50",
                   "uplift_benchmark","uplift_contract_p30","uplift_contract_p50","uplift_contract_p70","uplift_conservative","flag"]
    top_all = pd.concat([opp_o.assign(kind="overlap"), opp_b.assign(kind="brand")], ignore_index=True)[common_cols+["kind"]]
    top_all = top_all.sort_values("uplift_conservative", ascending=False)
    top_all.to_csv(os.path.join(cfg["paths"]["out_dir"], "top_opportunities.csv"), index=False, encoding="utf-8")

    print("Done. 输出在:", cfg["paths"]["out_dir"])

if __name__ == "__main__":
    parser = argparse.ArgumentParser()
    parser.add_argument("--config", default="config.yaml")
    args = parser.parse_args()
    main(args.config)
```

**怎么跑**

```bash
pip install pandas pyyaml numpy
python main.py --config config.yaml
```

输出目录（默认 `./out`）会有：

* `basic_overview_overlap.csv`（重叠基本面）
* `basic_overview_brand.csv`（品牌基本面）
* `opportunities_overlap.csv`（重叠机会）
* `opportunities_brand.csv`（品牌机会）
* `top_opportunities.csv`（合并后的 Top 清单，含保守 uplift 与红绿灯）

---

## 小贴士（避免踩坑）

* **样本阈值**：报告里“主结论”建议只用 `n≥30` 的行；`10≤n<30` 仅展示。
* **费率单位**：如果你的原始费率是 **0.061** 这种小数，改 `rate_unit` 并把 `uplift` 里的乘法保持一致即可。
* **性能**：单日 1.5 万站量 Pandas 足够；若更大，再换 DuckDB（SQL 同样套路）。
* **定义注释**：我在一页纸/Canvas里已固定；新增/共创字段我都会在报表尾部**标“定义的注释”**。

---

你把上面的**信息清单**发给我（或自己把 `config.yaml` 填好），就能在本地跑完整套“**基本面→机会→保守uplift**”分析。如果后面你要接入更多字段（比如省份分层、证据层级、订单密度定义变化），我可以在这套骨架上继续加模块，不改你的口径。
