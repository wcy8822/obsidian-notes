# 商户画像｜箭①+箭②试点跑批｜已确认口径与执行路线（锁定版）

> 用于固化“**箭① competitive\_overlap（结果型）** + **箭② brand\_name → brand\_level（计算型）**”的已确认口径与执行路线。此文档**锁定共识**，后续仅做轻量更正；每次只推进一个小步骤。

---

## A. 总原则（不变项｜已锁定）

* **三表口径**：仅用 `tag_code` 关联；不改你现网列名。
* **双口径产出**：同批次同时产 **Full（Tall+Hot）** 与 **Delta（tall\_delta+hot\_delta）**。
* **基线优先级**：`Tall(D-1)` 优先 → 外部 `S1`（可选）→ 防呆（首日默认 `suppress`）。
* **RAW1/RAW2 分工**：RAW1 只采+语法规范（ID/日期/布尔文本）；RAW2 做语义守门（值域、regex、TTL）。
* **择优合并**：Tall 基于 `conf = C_source^w1 × C_fresh^w2 × C_rule^w3 × C_match^w4` + 固定 tie-break；无合法候选才 `fallback`，并侧写 `used_fallback=1`。
* **快照/回放**：每日产出后固化 `snap_YYYYMMDD/{tall.csv, hot.csv, configs}`，保证回放与 Delta 可复现。
```
sed -i '' "s/pd.read_csv(fp, encoding=enc)/pd.read_csv(fp, dtype=str, encoding='utf-8', sep=None, engine='python')/g; s/pd.read_csv(fp, encoding=enc, sep=None, engine=\"python\")/pd.read_csv(fp, dtype=str, encoding='utf-8', sep=None, engine='python')/g" scripts/run_ingest_raw1.py

```

## B. 数据源与目录（已锁定）

```
data/raw/inbox/<batch_id>/
  ├─ s2/  # 区域（宽表，列名=tag_code）
  └─ s3/  # 商户（长表：tag_code, enum_code, value_text）
```

* 必备列：`store_id, date_ob`；时间支持多格式，RAW1 统一到 `observed_at`（ISO8601）。
* **S2（宽表）表头示例**：`store_id,date_ob,competitive_overlap,brand_name,...`
* **S3（长表）表头示例**：`store_id,date_ob,tag_code,enum_code,value_text`

---

## C. RAW1 语法规范口径（已锁定）

* **store\_id**：`strip`→`NFKC`→去成对引号→去 Excel 前导 `'`→空值词识别→`id_regex` 校验；非法行跳过并计 `missing_id`。
* **date\_ob**：多格式解析；无时分补 `T00:00:00`；失败用文件 `mtime` 兜底并记数。
* **值落位**：布尔文本仅解析到 `raw_value_code=1/0`；原文保留 `raw_value_text`；不做业务推断。
* **报告**：`raw1_report.json` 汇总 `missing_id/missing_obs/by_source/by_tag/value_hits`。

---

## D. RAW2 语义守门（已锁定）

* 按 `tag_spec.value_type` 激活单槽：`target_value_bool/number/string`。
* **bool/enum** 强值域：域外 → `OUT_OF_ENUM`；不强行改成兜底码。
* **regex**：如 `open_hours` 不过正则 → `REGEX_FAIL`。
* 产出证据：`evidence_state / reason_code / reason_text / ttl_days / conf`。

---

## E. 标签专属口径（已锁定）

### E1. competitive\_overlap（结果型）

* 合法枚举：`{1,0,99}`（`99` 仅作 Tall 兜底）。
* 建议 TTL：`7` 天；源权重：可抬高 `s2/s_overlap`。
* QA 关注：`out_of_enum_rate`≈0、`fallback_rate` 低、`freshness_lag_h` < 24h。

### E2. brand\_name → brand\_level（计算链路）

* **brand\_name**：`tag_enum` 中通过 `brand_aliases/keywords/alias_norm_rule` 做归一与 `match_score`；
* Tall 择优：按 `conf` 与 tie-break 选 1 个品牌码；无法判定才 `fallback=other`。
* **brand\_level**：

  1. **KA** 白名单（配置项：`ka_whitelist`）直接判 `KA`；
  2. 否则看阈值：品牌**有效站点数 ≥ cka\_threshold** 判 `CKA`（计数建议用 `Tall(D-1)`）；
  3. 其余 `小散`。支持 `min_days_to_downgrade` 防抖。

---

## F. Delta 双产出（已锁定）

* 变更类型：`CREATED, UPDATED, EXPIRED, FALLBACK_ADDED, FALLBACK_REMOVED, STATE_CHANGED`。
* 比较口径：`bool/enum` 比 `value_code`；`string/id` 比**规格化文本**（canonical）。
* 首日防呆：无基线默认 `suppress`（不输出全量 CREATED）。

---

## G. 执行路线图（大框架 → 小节点）

1. **RAW1**：投喂 S2/S3 → 跑 `run_ingest_raw1.py` → 查 `raw1_report.json`。
2. **RAW2**：`make raw2` → 查 `sample_raw2.csv`（箭①只 0/1；箭②有匹配信号）。
3. **Tall**：`make tall` → 查侧写（`value_source/used_fallback/conf/evidence_state`）。
4. **Hot + 快照**：`make hot && make snapshot`。
5. **Delta**：`make delta DATE=YYYYMMDD`（基于 `snap_D-1`）。

> 规则：每次只推进一个小步骤；你回复“继续”，再进入下一小步骤。

---

## H. 本回合状态

* 配置/目录：**已齐**（manifest、raw1\_fill、sources、ttl、merge\_policy.delta、qa）。
* 已对齐：数据源列名口径、RAW1/RAW2 分工、Tall 合并与 fallback、Delta 基线与防呆、brand\_level 判定框架。
* 待执行的小步骤：**Step 1｜RAW1 汇聚**（投喂本批、运行、贴报告摘要）。

---

## I. 你现在需要做

1. 在本地新建批次目录并投喂 S2/S3 文件（含 `competitive_overlap` 与 `brand_name`）。
2. 运行 RAW1 命令并把 `raw1_report.json` 的关键信息（missing\_id/missing\_obs/by\_tag 概要）贴回。

我保持“大框架 + 小节点”的完整记忆，随时答疑。你回复“继续”，我们就进入下一小步骤。



---
能放多文件没问题；你已经把“可选小开关”打开，更稳了。你说的“固定几套字段模板”，我建议这样落地，既安全又不容易踩坑：

# 方案总览（锁定做法）

* **一来源一模板**：同一批次可放多文件，但**不同表头模板用不同子目录**区分（=不同 `source_key`）。

  * 例：`s2a/、s2b/、s3a/、s3b/` 各自代表一套固定表头模板。
* **sources.yaml 精确适配**：每个模板单独写 `extractors` 块，明确必备列、别名列表 `prefer_cols`/`code_cols`。
* **最小关键列**：严格按口径校验；缺失的行在 RAW1 直接跳过并计数（你已经开启了防呆开关）。
* **模板固定后不再漂移**：后续若新增来源或新表头，**新建一个模板目录+一段映射**，不改旧模板，避免回放断裂。

---

# 模板定义（建议固定成下面 4 套起步）

> 你可以把实际表头贴我，我据此把模板名和映射改成 100% 匹配版。

## S2（宽表）

### 模板 S2A（推荐）

* 目录：`data/raw/inbox/<批次>/s2a/*.csv`
* 表头：`store_id,date_ob,competitive_overlap,brand_name`
* 说明：每列即 tag\_code；值可以是原文/别名/布尔文本（YES/NO/1/0）

### 模板 S2B（历史别名）

* 目录：`.../s2b/*.csv`
* 表头：`station_id,dt,overlap_flag,brand_text`
* 说明：与 S2A 同语义，但列名不同

## S3（长表）

### 模板 S3A（标准长表）

* 目录：`.../s3a/*.csv`
* 表头：`store_id,date_ob,tag_code,enum_code,value_text`

### 模板 S3B（码列别名）

* 目录：`.../s3b/*.csv`
* 表头：`store_id,date_ob,tag_code,brand_code,brand_name_raw`
* 说明：`brand_code→enum_code`，`brand_name_raw→value_text`

---

# sources.yaml（示例配置，粘上即可用）

> 路径：`conf/mappings/sources.yaml`。把每个模板写成一个 `extractor`。你实际表头若不同，我给你改成精准版。

```yaml
version: 1.2
extractors:

  # --- S2A: 宽表（推荐模板） ---
  s2a:
    mode: wide
    id_cols: [store_id]
    default_observed_at_col: date_ob
    tags:
      competitive_overlap: { prefer_cols: [competitive_overlap] }
      brand_name:          { prefer_cols: [brand_name] }

  # --- S2B: 宽表（历史别名模板） ---
  s2b:
    mode: wide
    id_cols: [station_id, store_id]     # 先试 station_id，再退 store_id
    default_observed_at_col: dt
    tags:
      competitive_overlap: { prefer_cols: [overlap_flag, competitive_overlap] }
      brand_name:          { prefer_cols: [brand_text, brand_name] }

  # --- S3A: 长表（标准） ---
  s3a:
    mode: long
    id_cols: [store_id]
    default_observed_at_col: date_ob
    long:
      tag_code_col:   tag_code
      value_code_col: enum_code
      value_text_col: value_text

  # --- S3B: 长表（码列别名模板） ---
  s3b:
    mode: long
    id_cols: [store_id]
    default_observed_at_col: date_ob
    long:
      tag_code_col:   tag_code
      value_code_col: brand_code
      value_text_col: brand_name_raw

normalize:
  trim: true
  to_half_width: true
  strip_html: true
```

> 使用：按文件实际表头放到对应子目录（s2a/s2b/s3a/s3b）。不要把两种表头混在同一目录里。

---

# “最小关键字段”硬口径（再次压实）

* **S2（宽）**：`store_id|station_id`、`date_ob`、`<若干 tag_code 列>`
* **S3（长）**：`store_id`、`date_ob`、`tag_code`、`enum_code` **或** `value_text`（至少一列要有值）
* RAW1 自动规范：`store_id` 引号/全角/Excel 前导 `'`、`date_ob` 多格式解析、布尔文本归到 `raw_value_code=1/0`。
* 行级策略：`store_id` 无效 ⇒ 跳过并记 `missing_id`；`date_ob` 不可解析 ⇒ 用 mtime 兜底并记 `missing_obs`；值列全空 ⇒ 该标签不产出。

---

# 你已经开启的小开关（👍）

把这段保留在 `conf/policies/raw1_fill.yaml`，现在就能兜住重复与临时文件：

```yaml
ingest:
  drop_exact_duplicates: true
  allow_multiple_candidates: true
  file_ignore_patterns: ["~$*", "*.tmp", "._*"]
```

---

# 建议的“模板固定化”流程（以后就按这个走）

1. **登记模板**：把每个模板的**表头**与**样例 3 行**固化到一个 `模板清单` Canvas（我可以新开一页来维护）。
2. **目录即模板**：每个模板对应固定子目录（`s2a/s2b/s3a/s3b/...`），sources.yaml 里有且仅有一段配置与之匹配。
3. **新增来源/字段**：**创建新模板**（新目录+新 extractor），不修改旧模板，避免“改配置影响历史回放”。
4. **上线前自测**：把新模板文件放到一个测试批次目录，跑 `RAW1`，看 `raw1_report.json` 的 `by_source/by_tag/value_hits` 是否命中预期。

---

# 下一步（你现在可以做两件事）

* **A 贴表头**：把你现有 S2/S3 各模板的**表头行**（和各 1–3 行样例）贴上来。我会据此把 `sources.yaml` 调成 100% 精准映射，并把“模板清单”写入 Canvas 锁定。
* **B 放文件跑 RAW1**：也可以直接放到 `data/raw/inbox/<批次>/s2a|s2b|s3a|s3b/` 按上面目录结构试跑；把 `raw1_report.json` 的摘要发我（`missing_id/missing_obs/by_tag`），我做体检。

如果你确认“以目录代表模板”的做法，那后面扩容新标签或新来源，只需要加一段 `extractor` 和一个新子目录，其他链路（RAW2/Tall/Hot/Delta/回放）不用动，稳定且回放友好。


---
太好了，样例看得很清楚。我把 **S1 / S2a / S2b / S3** 四套表头逐一“翻译”为我们的适配配置，并点出潜在坑位。你**无需改代码**，只要把下面这段合入 `conf/mappings/sources.yaml`（或按你现有结构补充），然后按目录投喂即可。

---

# 1) 精准适配方案（直接可用的 `sources.yaml` 片段）

```yaml
version: 1.3
extractors:

  # ===== S1：基线（宽表，仅提供 competitive_overlap）=====
  s1:
    mode: wide
    id_cols: [store_id]
    default_observed_at_col: date_ob
    tags:
      # 你表里叫 is_overlap；我们把它映射为 competitive_overlap
      competitive_overlap:
        prefer_cols: [is_overlap]   # 1/0 或 是/否 → 已在 boolean_truth 配好
      # S1 当前不提供 brand_name；若后续补列，再加 prefer_cols

  # ===== S2a：区域宽表（brand_name 主供）=====
  s2a:
    mode: wide
    id_cols: [store_id]
    default_observed_at_col: date_ob
    tags:
      # 品牌主列为 brand_name，回退到 brand_name_region
      brand_name:
        prefer_cols: [brand_name, brand_name_region]

  # ===== S2b：区域宽表（多标签混排，含 competitive_overlap / brand_name 等）=====
  s2b:
    mode: wide
    id_cols: [store_id]
    default_observed_at_col: observed_at   # 你这张表最后一列就是 observed_at
    tags:
      competitive_overlap:
        # 你的列名就是 competitive_overlap；兜底兼容 is_overlap/overlap_flag 等历史名
        prefer_cols: [competitive_overlap, is_overlap, overlap_flag]
      brand_name:
        # 这张表里叫 brand_name；同时兼容历史截断/别名（brand_nar/brand_text）
        prefer_cols: [brand_name, brand_nar, brand_text]

  # ===== S3：商户长表（标准）=====
  s3:
    mode: long
    id_cols: [store_id]
    default_observed_at_col: date_ob
    long:
      tag_code_col:   tag_code
      value_code_col: enum_code
      value_text_col: value_text

normalize:
  trim: true
  to_half_width: true
  strip_html: true
```

> 放置规则：把你截图里的四类文件分别放到 `data/raw/inbox/<批次>/s1/`, `.../s2a/`, `.../s2b/`, `.../s3/` 目录中。**目录名=source\_key**，系统靠这个识别来源，不需要你额外填 “来源列”。

---

# 2) 字段口径核对与风险提示

## S1（基线）

* ✅ 必备命中：`store_id`、`date_ob`、`is_overlap`（→ `competitive_overlap`）
* ⚠️ `is_overlap_source`（“商户/区域”）只是**描述来源**，不参与决策；我们会保存在 `origin_cols` 侧写，**不映射到 tag**。
* ✅ 值域：`0/1` 或 `商户/区域/是/否` 都没问题，`boolean_truth` 已收录“是/否”。

## S2a（brand\_name 主供）

* ✅ 必备命中：`store_id`、`date_ob`、`brand_name`；回退 `brand_name_region`。
* ⚠️ 品牌原文可能出现“其他/民营小散”等**类别词**，RAW2 会尝试别名归一；匹配不了的会 `LOW_CONF` 或 fallback=other。

  * 如比例偏高，**补 `tag_enum.brand_aliases/keywords`** 即可（不用动代码）。

## S2b（多标签宽表）

* ✅ `competitive_overlap` 值出现“是/否”→ 已按布尔词典转换为 `1/0`；
* ✅ `brand_name` 存在；`brand_level` 虽然也在表里，但我们将**忽略**这列（因为你的口径是 brand\_level 由 brand\_name+计数**计算**得出，而不是“结果型直取”）。

  * 若你确实想把该列作为**候选证据**参与“计算后对比”，我们可以把它作为 `brand_level_hint` 的**辅证**字段（不进入 tag 候选，仅影响 `reason_text/white_list`），现在先不启用，避免混淆。

## S3（长表）

* ✅ 标准长表：`tag_code=competitive_overlap`、`enum_code=1/0`；这会与 S1/S2 的候选一起在 Tall 里择优。
* ⚠️ 你这批 S3 样例没有 `brand_name`，没问题；后续要跑品牌时，加一条 `tag_code=brand_name` 的记录即可。
* ✅ 其他列（`city_name/校验人/验证逻辑` 等）会进入 `origin_cols` 侧写，方便举证但不参与决策。

---

# 3) RAW1 配置小开关（你已开启，复述对齐）

```yaml
ingest:
  drop_exact_duplicates: true          # 完全重复行只保留一条
  allow_multiple_candidates: true      # 同键不同值 → 全保留，Tall 决策
  file_ignore_patterns: ["~$*", "*.tmp", "._*"]
```

---

# 4) 两个“易错点”再强调一下

1. **超长 `store_id`**（19 位以上）从 Excel 导出时容易被转成科学计数/失真。

   * 导出 CSV 前把该列**设为文本**，或在 CSV 中确保没有科学计数法字符；我们在 RAW1 里是按“**字符串**”读取，但 Excel 可能已经破坏了数值。
2. **日期格式**：`2025/9/19`、`2025-09-19`、`20250919` 都能识别；若有 `2025-9-1 8:00` 也会被 parse 并补 00 秒。实在解析不了就用文件 mtime 并计 `missing_obs`。

---

# 5) 下一拍如何执行

1. 把四类文件放入对应目录：`s1/`, `s2a/`, `s2b/`, `s3/`。
2. 跑 RAW1：

```bash
python scripts/run_ingest_raw1.py --root . --manifest conf/manifest.yaml --batch_id <批次>
```

3. 回我 `runs/<批次>/raw1_report.json` 的摘要（`missing_id / missing_obs / by_tag`）+ `data/raw/sample/sample_raw1.csv` 表头与 3 行，我做体检。
   你回复“继续”，我就带你进入 **Step 2｜RAW2 语义守门** 的确认与微调（如果需要，我也会根据这次报表直接给 `tag_enum.brand_aliases/keywords` 的补充建议）。


---
妥！你这批次路径是
`/Users/didi/Downloads/panth/tag_ct_local/data/raw/inbox/20250920_0656/s2`
⇒ **batch\_id = `20250920_0656`**（我们后续命令都用这个），**as\_of\_date = `20250920`**（给 Delta 用）。

下面是一整套**可粘贴即跑**的命令：从虚拟环境到 Full+Delta 全流程，含自检。默认 macOS bash/zsh。

```bash
# 0) 进工程目录
cd /Users/didi/Downloads/panth/tag_ct_local

# 1) 虚拟环境（可重复执行；已存在则复用）
/usr/bin/python3 -m venv .venv
source .venv/bin/activate
python -m pip install -U pip
pip install -U pandas pyyaml python-dateutil chardet

# 2) 快速自检（manifest 键路径 & 合同占位）
python scripts/validate_manifest_keys.py --root . --manifest conf/manifest.yaml
python scripts/validate_pipeline_contracts.py --root . || true

# 3) 跑 RAW1（按你给的批次号）
python scripts/run_ingest_raw1.py --root . \
  --manifest conf/manifest.yaml \
  --batch_id 20250920_0656

# （可选）看一眼摄取报告
echo "---- RAW1 report ----"
cat runs/20250920_0656/raw1_report.json || true

# 4) RAW2 → Tall → Hot → 快照（Full 产物）
make raw2
make tall
make hot
make snapshot

# 5) Delta（相对上一版；日期用 20250920）
make delta DATE=20250920

# 6) 产物位置速查
echo "Tall   =>" $(ls -1 output/tall/tall_*.csv | tail -n 1)
echo "Hot    =>" $(ls -1 output/hot/hot_*.csv  | tail -n 1)
echo "ΔTall  =>" $(ls -1 output/delta/tall_delta_*.csv | tail -n 1)
echo "ΔHot   =>" $(ls -1 output/delta/hot_delta_*.csv  | tail -n 1)
```

### 小提醒（避免踩坑）

* 你的 S2 目录已就位；若同批还有 S1/S3/S3b，把文件放到：

  * `data/raw/inbox/20250920_0656/s1/`
  * `data/raw/inbox/20250920_0656/s3/`
  * `data/raw/inbox/20250920_0656/s3b/`
* **Excel 可能破坏长整型 `store_id`**：导出 CSV 前把该列设为“文本”；我们按“字符串”读，但被 Excel 变成科学计数就救不回来了。
* 首日没有快照时，`delta` 会按配置 **suppress**（不输出全量 CREATED）；等第二天再对比就有增量了。

跑完后，把这三个东西贴我做“读片体检”：

1. `runs/20250920_0656/raw1_report.json` 摘要（missing\_id/missing\_obs/by\_tag）
2. `data/raw/sample/sample_raw1.csv` 的表头+3行
3. 四个产物（Tall/Hot/ΔTall/ΔHot）各 3 行样例

你回“继续”，我就带你进入下一小步骤（RAW2 的语义体检与 `brand_name` 别名/规则的微调）。
