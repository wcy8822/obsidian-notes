
你说得对：**批次号被硬编码**会把成本钉死。给你一套“反硬编码总方案”，一把梭把这类问题（不仅是 batch\_id）全部消灭，同时让链路依旧递延、可追溯。

---

# 总思路（一句话）

把“写死的值”换成：**自动解析器 + 模板化路径 + 运行上下文（run\_ctx） + 白名单与哈希链断言**。
批次、source、输入文件清单、输出去向都在运行时解析生成；任何不是由解析器/ctx推导出的路径，一律 fail-fast。

---

## 1) 批次解析器（Batch Resolver）：**不再传固定批次也能跑**

* **解析方式**：从 `env` 与 `ROOT` 推导输入根目录：

  * test → `${ROOT}/data/test/inbox/`
  * prod → `${ROOT}/data/raw/inbox/`
* **选择策略（四选一）**：

  * `--batch latest`：自动选最新目录（按 `YYYYMMDD_HHMM` 排序）
  * `--batch 20250920_0656`：指定批次
  * `--since-days 3`：近 N 天内所有批次
  * `--batch-range 20250901_0000..20250921_2359`：范围回放
* **source 自动发现**：`--sources all` 时，遍历该批次下的子目录名（`s1,s2,s3,s4`），不存在就跳过并记入 metrics。

> 产出一个**计划文件**：`plan.json`（本次要跑的 {batch, source} 组合与每个组合的输入文件清单）。

---

## 2) 模板化路径：**路径由模板 + 变量渲染，不再硬写**

* 统一模板（由程序内置，不允许直接传入绝对路径覆盖）：

  * `input_glob   = {inbox_root}/{batch}/{source}/*.{csv,xlsx}`
  * `debug_dir    = {out_root}/debug/{batch}/{source}`
  * `norm_csv     = {debug_dir}/01_normalized.csv`
  * `prep_csv     = {debug_dir}/02_preprocessed.csv`
  * `cand_csv     = {debug_dir}/03_candidates.csv`
  * `rank_csv     = {debug_dir}/04_ranked.csv`
  * `agg_csv      = {debug_dir}/05_aggregated.csv`
  * `final_csv    = {out_root}/clean/{batch}/{source}/brand_cleaned.csv`
  * `audit_jsonl  = {out_root}/audit/{batch}/{source}/audit.jsonl`
* `inbox_root` 与 `out_root` 由 `--env` 决定：
  `test → /data/test/inbox` 与 `/outputs_test`；`prod → /data/raw/inbox` 与 `/outputs`。

---

## 3) 运行上下文（run\_ctx.json）：**一次生成，全程只认它**

* **批次级**：`${out_root}/debug/{batch}/run_ctx.json`（含多 source）
* 包含：`spec_version, env, dict_mode, root, batch, sources, templates, resolved_paths[batch][source], md5_placeholders`
* **B 之后**写回 `md5.B_out_normalized[source]`；后续每步按 source 递延补齐 md5。

> **禁止**在 B–G 传 `--in/--out` 原始路径；必须 `--ctx run_ctx.json --source s1`。任何手动路径参数 → 当场报错。

---

## 4) “计划→执行”双命令：**plan 拟定，flow 串跑**

* `brandctl plan --env test --batch latest --sources all`

  * 产出 `plan.json` + `run_ctx.json`，列明将要跑的批次、source、文件清单、目标产出位置。
* `brandctl flow --ctx <run_ctx.json>`

  * 按 ctx 串起 A→B→C→D→E→F→G，逐 source 执行；期间自动写 `delivery_manifest.json` 与 `00_assert.txt`。

---

## 5) 白名单 & 哈希链断言：**越权即死**

* **白名单 I/O**（运行时钩子拦截 open/read/write）：

  * 仅允许以下前缀（按 env 自动切换）

    * `${ROOT}/data/test/inbox/{batch}/{source}/` 或 `${ROOT}/data/raw/inbox/{batch}/{source}/`
    * `${ROOT}/outputs_test/.../{batch}/{source}/` 或 `${ROOT}/outputs/.../{batch}/{source}/`
* **哈希链**：

  * 本步输入 md5 必须等于上一步输出 md5；否则 fail。
  * `delivery_manifest.json` 必须形成连续链（A\_out→B\_in→…→final\_out）。
* **新增断言写入 `00_assert.txt`**：

  * `PASS/FAIL | plan_used`：是否使用了 plan/run\_ctx
  * `PASS/FAIL | io_whitelist_enforced`：I/O 是否全部在白名单内
  * `PASS/FAIL | input_matches_prev_md5`：递延 md5 是否吻合
  * `PASS/FAIL | env_path_match`：`--env` 与 out\_root 是否一致（prod→`/outputs/`，test→`/outputs_test/`）

---

## 6) 配置优先级（避免“再生硬编码”）

**CLI > 环境变量 > policy.yaml > 内置默认**

* 例：`--batch-range` 覆盖 `BATCH_RANGE` 环境变量；实在没给，再看 policy；最后走默认（`latest`+`sources all`）。

---

## 7) 其他“常见硬编码坑”与统一解法

| 容易被写死的点   | 正确做法                                                                                    |
| --------- | --------------------------------------------------------------------------------------- |
| 批次号       | 用 **Batch Resolver**（latest/范围/近N天），写入 plan/ctx                                         |
| source 列表 | `--sources all` 自动发现；也支持 `--sources s1,s3`                                              |
| 字典路径      | 固定从 `${ROOT}/data/ref` 读取；只读；写入即 fail                                                   |
| 后缀/停用词规则  | 由 `${ROOT}/conf/brand_cleaning_rules.yaml` 驱动；版本号写入 ctx/manifest                        |
| 输入扩展名     | 模板 `*.{csv,xlsx}`，可在 policy 中配置扩展集合                                                     |
| 分隔符/编码    | 统一 UTF-8，无 BOM；中文分号 `；` 配置在 policy 中（但默认不建议改）                                           |
| 置信度分档     | 枚举 `{100,85,80,45}` 固化在 policy；越权改档 → 断言失败                                              |
| 候选四条件     | 固化校验：`is_active=1 ∧ white_list=1 ∧ is_default=FALSE ∧ enum_code LIKE BRAND_0%`；违背即 fail |
| 输出目录      | 由 env 派生 out\_root；禁止自定义绝对路径覆盖                                                          |

---

## 8) 你可以直接发给 trace 的「改造 Prompt」（精简版）

```
【改造目标】移除所有硬编码（尤其 batch_id），实现：Batch Resolver + 模板化路径 + run_ctx + plan/flow + 白名单 & 哈希链断言。

【必须交付】
1) brandctl plan --env <test|prod> --batch <latest|YYYY..|--since-days|--batch-range> --sources <all|s1,s3>
   - 生成 plan.json（本次运行的批次与文件清单）与 run_ctx.json（批次级，含多 source）
2) brandctl flow --ctx <run_ctx.json>
   - 串跑 A→G；产出 brand_cleaned.csv / audit.jsonl / 00_assert.txt / delivery_manifest.json

【硬性约束】
- B–G 只接受 --ctx 与 --source，不接受 --in/--out 等路径型参数；传入即报错
- 所有 I/O 必须在白名单前缀内；越权即 fail（写入 00_assert.txt）
- 本步输入 md5 必须等于上一步输出 md5（递延链）；否则 fail
- 断言必须包含：plan_used / io_whitelist_enforced / input_matches_prev_md5 / env_path_match

【验收】
- 我仅看 plan.json（确认拿的是 latest/范围）、run_ctx.json、00_assert.txt（三条断言 PASS）、delivery_manifest.json（md5 链连续）
- 任何一步未使用 plan/ctx 或访问白名单外路径，视为未交付
```

---

## 9) 你这边的使用姿势（以后都不用管批次号）

* **最新一批**（测试）：
  `brandctl plan --env test --batch latest --sources all` → `brandctl flow --ctx .../run_ctx.json`
* **近 3 天全部批次**（正式）：
  `brandctl plan --env prod --since-days 3 --sources s1,s2` → `brandctl flow --ctx ...`
* **回放一个区间**：
  `brandctl plan --env prod --batch-range 20250901_0000..20250921_2359 --sources all` → `flow`

---

这样一改，**批次号、source、输入清单**都从运行时解析，**路径由模板渲染**，**链路靠 ctx 与 md5 递延**，再也不会被“硬编码”卡住。需要的话，我可以把这套“反硬编码条款”收进你的总览文档（canvas），以后新同学和 trace 都照这份跑，不会走样。

```
【任务目标】
在本机按“测试输入/输出隔离 + 读取 prod 字典”的模式，分步执行门店品牌清洗（Step 1–6），每步都导出中间产物与断言结果；最终产出宽表（store_id 唯一、不丢行）与审计日志。任何断言不满足需立即失败并打印最小复现样例（含路径/行号/建议修复）。

【固定口径】
- ROOT = /Users/didi/Downloads/panth/tag_ct_local
- 批次与槽位：batch_id=20250920_0656，slot=s1（小写）
- 环境：--env=test（测试输入/输出路径），但字典默认读取 prod（prod_mirror）
- 候选入池限制：is_active=1 AND white_list=1 AND is_default=FALSE AND enum_code LIKE 'BRAND_0%'
- 输出必须为宽表：store_id 唯一；不丢行；多值折叠到 raw_values / preliminary_results，使用中文分号「；」分隔且一一对应、顺序稳定（长表按行序，宽表按列号序）
- 置信度四档：100 / 85 / 80 / 45（45 代表 40–50 档的中值）；枚举外禁止出现
- 胜出逻辑 win_logic ∈ {一致直选, 票数×sort_order, 兜底, 待人工复核}
- sort_order 越大优先级越高，是候选排序和门店聚合的第一决胜项
- 默认品牌（is_default=TRUE）只允许兜底，严禁出现在候选池

【字典与路径（只读/只写约束）】
- 只读字典（prod）：${ROOT}/data/ref
  - tag_enum.csv, stop_rule.xlsx
  - 规则：${ROOT}/conf/brand_cleaning_rules.yaml
- 测试输入：${ROOT}/data/test/inbox/20250920_0656/s1/*.csv
- 测试输出（清洗）：${ROOT}/outputs_test/clean/20250920_0656/s1/brand_cleaned.csv
- 测试输出（审计）：${ROOT}/outputs_test/audit/20250920_0656/s1/audit.jsonl
- 调试中间产物目录：${ROOT}/outputs_test/debug/20250920_0656/s1/
- 严禁对 /data/ref 与 /data/test/ref 写入

【你要执行的唯一命令】
请按下述命令执行（如需调用多次，仅修改 --debug-steps 范围）。执行前若目录不存在需自动创建。
python brandctl.py clean \
  --env test \
  --dict-mode prod_mirror \
  --in  "/Users/didi/Downloads/panth/tag_ct_local/data/test/inbox/20250920_0656/s1/*.csv" \
  --out "/Users/didi/Downloads/panth/tag_ct_local/outputs_test/clean/20250920_0656/s1/brand_cleaned.csv" \
  --policy "/Users/didi/Downloads/panth/tag_ct_local/conf/brand_cleaning_rules.yaml" \
  --audit "/Users/didi/Downloads/panth/tag_ct_local/outputs_test/audit/20250920_0656/s1/audit.jsonl" \
  --id-col store_id \
  --raw-col raw_brand_name \
  --wide-raw-prefix raw_value_ \
  --debug-steps 1,2,3,4,5,6 \
  --assert-idempotent

【分步交付与中间产物（必须生成以下文件）】
Step 1 环境与路径自检（只探测）
- 00_env.json：打印 {env, dict_mode, dict_root, input_glob, output_path, audit_path}
- 00_assert.txt（新增断言行）：
  - PASS/FAIL | env_path_match | env=test 时输出路径必须在 /outputs_test/
  - PASS/FAIL | dict_mode_effective | prod_mirror 时 dict_root=/data/ref
Step 2 输入标准化（长/宽→统一长表）
- 01_normalized.csv：两列 store_id, raw_value（顺序稳定）
- 01_metrics.json：{"rows_in":X,"stores_in":Y,"rows_normalized":Z,"stores_after_groupby":Y}
- 00_assert.txt 追加：
  - PASS/FAIL | normalized_counts | rows_normalized>=stores_in 且 stores_after_groupby==stores_in
Step 3 预处理链（仅文本清洗）
- 02_preprocessed.csv：store_id, raw_value, cleaned, evidence_steps_json
- 02_metrics.json：记录各预处理步骤计数
Step 4 候选入池与过滤（不排序，不聚合）
- 03_candidates.csv：store_id, cleaned, enum_code, enum_label, hit_type, raw_score, sort_order, blocked_reason|null
- 03_metrics.json：{"candidates_total":A,"blocked_default":B,"blocked_inactive":C,"blocked_nonwhite":D,"blocked_prefix":E}
- 00_assert.txt 追加：
  - PASS/FAIL | default_not_in_candidates | 候选集中严禁 is_default=TRUE（如发生，列举3条最小复现）
  - PASS/FAIL | whitelist_active_prefix | 任何候选必须满足 is_active=1 & white_list=1 & BRAND_0*
Step 5 候选排序与单值置信度分档（逐值）
- 排序铁律：①sort_order(降) > ②raw_score(降) > ③别名长度(降) > ④enum_code(升)
- 04_ranked.csv：store_id, cleaned, top_enum_code, top_enum_label, win_reason, top_score, confidence_bin(100/85/80/45)
- 04_metrics.json：四档分布
- 00_assert.txt 追加：
  - PASS/FAIL | conf_bins | 置信度仅允许 {100,85,80,45}
Step 6 门店聚合与兜底（逐值→门店宽表）
- 05_aggregated.csv（最终宽表结构）：
  store_id, tag_code, raw_values, preliminary_results, brand_final, win_logic, confidence, is_valid_brand, is_fallback, trace_id
- 05_metrics.json：{"stores_in":Y,"stores_out":Y,"conflict_resolved":M,"fallback_used":N}
- 00_assert.txt 追加：
  - PASS/FAIL | no_row_loss | stores_out==stores_in
  - PASS/FAIL | unique_store | 结果 store_id 无重复
  - PASS/FAIL | pairwise_align | raw_values 与 preliminary_results 的「；」分隔项数严格相等
Step 7 最终产物与审计等长
- brand_cleaned.csv：需与 05_aggregated.csv 等价
- audit.jsonl：逐 raw_value 记录 {store_id, raw_value, cleaned, candidates[], top_decision, evidence_steps[]}
- 00_assert.txt 追加：
  - PASS/FAIL | audit_length | audit.jsonl 行数 == 01_normalized.csv 行数
Step 8 幂等性（自动二次运行）
- 00_assert.txt 追加：
  - PASS/FAIL | idempotency | 两次 brand_cleaned.csv 的 MD5 一致

【结果回传要求】
执行完成后，请只回传以下内容的摘要与路径（无需贴大文件）：
1) 00_assert.txt 的最后 15 行（含所有 PASS/FAIL 汇总）
2) 00_env.json
3) 01_metrics.json、03_metrics.json、04_metrics.json、05_metrics.json
4) 05_aggregated.csv 的前 10 行
如有 FAIL，请同时回传最小复现样例（含：输入样例3行、相关中间行、你的修复建议至少1条）。


```