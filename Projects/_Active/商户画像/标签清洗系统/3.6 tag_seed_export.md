

收到。先把需求“口径”拉齐一下，你确认后回我数字【3】，我再开写代码。

---
好的，收到你的“主键= **store\_id+pop\_id+tag\_code**”的要求，其它口径保持一致。我直接给你长表穷尽版脚本（不丢 `pop_id`，穷尽三来源且清洗无效值，按优先级排序；为保证“穷尽”不被误删，**去重维度采用 `store_id+pop_id+tag_code+value_text`**，这样同一主键可以并存多值）。

把下面保存为 `tag_seed_export_long.py`，用 `python3` 运行。

```python
#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
tag_seed_export_long.py
- 输入 Excel
- 仅产出 tag_code=brand_name（可用 --tag-map 扩展更多标签）
- 对 store_name -> pop_name -> party_first_name 三列进行“穷尽”抽取（非空、非无义值才产出）
- 输出长表：每个有效来源各出一行
- 排序：store_name 优先，再 pop_name，再 party_first_name
- 去重：为保留多值，使用 (store_id, pop_id, tag_code, value_text) 维度去重
- 输出字段：store_id, pop_id, tag_code, value_text, value_type, date_ob
"""

import argparse
from pathlib import Path
from datetime import datetime
from zoneinfo import ZoneInfo
import pandas as pd
import re
import sys

# 认为“无意义”的占位（大小写/空白已在清洗环节处理）
DEFAULT_NULL_TOKENS = {
    "", "-", "--", "—", "null", "none", "na", "n/a", "nan", "无", "未知"
}

PRIORITY_DEFAULT = ["store_name", "pop_name", "party_first_name"]

def parse_tag_map(s: str) -> dict:
    """'brand_name=store_name,pop_name,party_first_name;city=city_std,city_raw'"""
    if not s:
        return {}
    tag_map = {}
    for part in s.split(";"):
        part = part.strip()
        if not part:
            continue
        if "=" not in part:
            raise ValueError(f"--tag-map 片段缺少 '='：{part}")
        tag, fields = part.split("=", 1)
        tag = tag.strip()
        fields = [f.strip() for f in fields.split(",") if f.strip()]
        if not tag or not fields:
            raise ValueError(f"--tag-map 片段格式错误：{part}")
        tag_map[tag] = fields
    return tag_map

def normalize_text(x) -> str:
    """基础清洗：全角空格->半角，去首尾空白，统一为 str"""
    if pd.isna(x):
        return ""
    s = str(x).replace("\u3000", " ").strip()
    return s

def is_meaningful(s: str, null_tokens:set) -> bool:
    if s is None:
        return False
    s_norm = s.strip()
    if s_norm.lower() in null_tokens:
        return False
    return len(s_norm) > 0

def ensure_cols(df: pd.DataFrame, cols:list[str]):
    missing = [c for c in cols if c not in df.columns]
    if missing:
        raise KeyError(f"源表缺少必要字段：{missing}")

def run(input_path:str, sheet, output_dir:str, tag_map_str:str, null_tokens:set):
    input_path = Path(input_path)
    output_dir = Path(output_dir) if output_dir else input_path.parent

    # tag_map 合并（默认仅 brand_name）
    default_tag_map = {"brand_name": PRIORITY_DEFAULT}
    user_tag_map = parse_tag_map(tag_map_str)
    tag_map = {**default_tag_map, **user_tag_map}

    read_kwargs = {"engine": "openpyxl"}
    if isinstance(sheet, int):
        read_kwargs["sheet_name"] = sheet
    elif isinstance(sheet, str) and sheet:
        read_kwargs["sheet_name"] = sheet

    df = pd.read_excel(input_path, **read_kwargs)

    # 必备字段
    ensure_cols(df, ["store_id", "pop_id"])

    # 清洗所有候选列（存在才清洗）
    for cols in tag_map.values():
        for c in cols:
            if c in df.columns:
                df[c] = df[c].map(normalize_text)

    # 生成长表记录
    records = []
    date_today = datetime.now(ZoneInfo("Asia/Tokyo")).date().isoformat()

    for _, row in df.iterrows():
        store_id = row["store_id"]
        pop_id = row["pop_id"]

        for tag_code, fields in tag_map.items():
            # 对每个候选字段“穷尽”产出
            for rank, col in enumerate(fields):
                if col not in df.columns:
                    continue
                val = row[col]
                if not isinstance(val, str):
                    val = normalize_text(val)
                if is_meaningful(val, null_tokens):
                    records.append({
                        "store_id": store_id,
                        "pop_id": pop_id,
                        "tag_code": tag_code,
                        "value_text": val,
                        "value_type": col,     # 标记来源
                        "priority_rank": rank, # 便于排序展示
                        "date_ob": date_today,
                    })

    if not records:
        print("[WARN] 没有可产出的有效记录。", file=sys.stderr)
        out_df = pd.DataFrame(columns=["store_id","pop_id","tag_code","value_text","value_type","date_ob"])
    else:
        long_df = pd.DataFrame.from_records(records)

        # 排序：同店同标签按优先级（store_name > pop_name > party_first_name）
        long_df = long_df.sort_values(
            by=["store_id", "pop_id", "tag_code", "priority_rank"],
            ascending=[True, True, True, True]
        )

        # 去重：允许并存多值，但去掉同文重复
        long_df = long_df.drop_duplicates(subset=["store_id", "pop_id", "tag_code", "value_text"], keep="first")

        out_df = long_df[["store_id","pop_id","tag_code","value_text","value_type","date_ob"]].copy()

    ts = datetime.now(ZoneInfo("Asia/Tokyo")).strftime("%Y%m%d_%H%M%S")
    out_path = output_dir / f"tag_seed_long_{ts}.csv"
    out_df.to_csv(out_path, index=False, encoding="utf-8-sig")

    # 汇总
    total = len(out_df)
    by_type = out_df["value_type"].value_counts(dropna=False).to_dict() if total else {}
    print(f"[DONE] 输出：{out_path}")
    print(f"[STAT] 行数={total}（维度允许多值：同一 store_id+pop_id+tag_code 可有多行）")
    print(f"[STAT] 来源分布={by_type}")

def build_parser():
    p = argparse.ArgumentParser(description="标签长表导出（穷尽候选，含 pop_id）")
    p.add_argument("--input", required=True, help="输入 .xlsx 路径")
    p.add_argument("--sheet", help="Sheet 名或序号")
    p.add_argument("--output-dir", default="", help="输出目录，默认与输入同目录")
    p.add_argument(
        "--tag-map",
        default="",
        help=("动态扩展标签与候选列：tag=col1,col2;tag2=colA,colB "
              "示例：brand_name=store_name,pop_name,party_first_name;brand_level=brand_level_std,brand_level_raw")
    )
    p.add_argument(
        "--null-tokens",
        default="",
        help="额外无意义占位（逗号分隔），会并入默认集：例如 '无,未知,-,--'"
    )
    return p

def main():
    args = build_parser().parse_args()

    # sheet 兼容数字/字符串
    sheet = None
    if args.sheet:
        if re.fullmatch(r"\d+", str(args.sheet)):
            sheet = int(args.sheet)
        else:
            sheet = str(args.sheet)

    # 合并 null tokens
    null_tokens = set(t.strip().lower() for t in (args.null_tokens.split(",") if args.null_tokens else []))
    null_tokens = {t for t in null_tokens if t}
    null_tokens |= set(x.lower() for x in DEFAULT_NULL_TOKENS)

    run(
        input_path=args.input,
        sheet=sheet,
        output_dir=args.output_dir,
        tag_map_str=args.tag_map,
        null_tokens=null_tokens
    )

if __name__ == "__main__":
    main()
```

### 怎么跑

```bash
# 安装依赖（如未安装）
/usr/bin/python3 -m pip install --user --upgrade pip pandas openpyxl

# 执行（仅 brand_name；穷尽三来源）
/usr/bin/python3 tag_seed_export_long.py \
  --input "/Users/didi/Downloads/panth/tag_ct/total_list_full_58k.xlsx" \
  --sheet 0 \
  --tag-map "brand_name=store_name,pop_name,party_first_name"
```

* 输出：`tag_seed_long_YYYYMMDD_HHMMSS.csv`
* 字段顺序：`store_id,pop_id,tag_code,value_text,value_type,date_ob`
* 同一 `store_id+pop_id+tag_code` 可存在多行（多值并存），但同文只保留一份。

### 快速扩展更多标签

```bash
/usr/bin/python3 tag_seed_export_long.py \
  --input "/Users/didi/Downloads/panth/tag_ct/total_list_full_58k.xlsx" \
  --tag-map "brand_name=store_name,pop_name,party_first_name;brand_level=brand_level_std,brand_level_raw"
```

### 说明

* 你指定的“主键= `store_id+pop_id+tag_code`”是**维度键**；为保留多值并存，我在去重时增加了 `value_text`，避免把多值误删。表面看会重复维度键，但这是**预期行为**（长表模式）。后续若你要改为**单值主键**（每维度只留一个值），可以再加一个“聚合策略”开关（如选优先级最高来源）。


---
# 任务理解（v1.0）

* **输入文件**：`/Users/didi/Downloads/panth/tag_ct/total_list_full_58k.xlsx`（默认读取首个 sheet；如需指定请说明）。

* **输出字段**（逐行产出，不做聚合/去重）：

  1. `store_id`：原样取
  2. `pop_id`：原样取
  3. `tag_code`：**固定写死为 `brand_name`**（本次就是为“品牌名”这个标签产出值）
  4. `value_text`：从以下字段按优先级取其**第一个非空、非纯空白**值：
     `store_name` → `pop_name` → `party_first_name`
  5. `value_type`：标记 `value_text` 的取值来源，枚举：`store_name` / `pop_name` / `party_first_name` / `EMPTY`（都取不到时）
  6. `date_ob`：填**当天日期**，时区按 Asia/Tokyo，格式 `YYYY-MM-DD`（今天为 `2025-09-20`）

* **基础清洗**（轻量）：

  * 去掉取值首尾空白。
  * 将全角空格统一为半角空格。
  * 若最终三处都为空，`value_text` 置空字符串，`value_type=EMPTY`。

* **不做的事**（本轮不包含）：

  * 不做品牌识别/正则抽取/字典清洗（`value_text` 只是“候选原文”，后续可交由 brand\_cleaner 再清洗）。
  * 不做去重与合并（如需按 `store_id+tag_code` 去重可再开开关）。

* **输出**：

  * CSV 与 XLSX 各一份（便于下游）：
    `brand_name_seed_{YYYYMMDD_HHMMSS}.csv` / `.xlsx`
  * 字段顺序：`store_id,pop_id,tag_code,value_text,value_type,date_ob`

> 若你更希望 `tag_code` 直接沿用输入表中的同名列，而不是写死为 `brand_name`，我也可以切换到“**沿用输入 tag\_code**”模式；但按你这次的描述，“本轮就是产出 brand\_name 这个标签”的理解更贴合。

确认无误请回【3】。接下来我会直接给出一键可跑的 Python 脚本（含：路径/编码/空值处理/时区日期/CSV+XLSX 双落地）。随后要不要加“空值率统计+样例抽样”小校验，也可以一并做进去。

稳了，我直接给你一键可跑的脚本，满足这 3 点：

1. 输出 **CSV**；2) **主键去重**（`store_id+pop_id+tag_code`）；3) 未来可**快捷扩展更多 tag\_code 的取值优先级**（命令行一行配置即可）。

把下面保存成 `tag_seed_export.py`，本地 Python 3.9+ 运行（需要 `pandas`、`openpyxl`）。

```python
#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
tag_seed_export.py
- 从 Excel 读取源数据
- 按 tag_code 的字段优先级抽取 value_text，并标注 value_type
- 以 store_id+pop_id+tag_code 为主键去重
- 仅输出 CSV
- 默认支持 brand_name=store_name,pop_name,party_first_name
- 可通过 --tag-map 快速扩展更多标签： a=b,c; x=y,z
"""

import argparse
import sys
from pathlib import Path
from datetime import datetime
from zoneinfo import ZoneInfo
import re

import pandas as pd

# -------------------------
# 工具函数
# -------------------------
NULL_LIKE = {None, "", " ", "null", "none", "na", "n/a", "nan", "无", "未知", "Null", "NULL", "N/A", "NA"}

def is_blank(x) -> bool:
    if pd.isna(x):
        return True
    if isinstance(x, str):
        s = x.replace("\u3000", " ").strip()  # 全角空格→半角，去首尾空白
        return s == "" or s in NULL_LIKE
    return False

def clean_str(x) -> str:
    if pd.isna(x):
        return ""
    if not isinstance(x, str):
        x = str(x)
    return x.replace("\u3000", " ").strip()

def parse_tag_map(s: str) -> dict:
    """
    解析 --tag-map 字符串：例如
    'brand_name=store_name,pop_name,party_first_name;foo=bar,baz'
    返回：{"brand_name":["store_name","pop_name","party_first_name"], "foo":["bar","baz"]}
    """
    if not s:
        return {}
    tag_map = {}
    for part in s.split(";"):
        part = part.strip()
        if not part:
            continue
        if "=" not in part:
            raise ValueError(f"--tag-map 片段缺少 '='：{part}")
        tag, fields = part.split("=", 1)
        tag = tag.strip()
        fields = [f.strip() for f in fields.split(",") if f.strip()]
        if not tag or not fields:
            raise ValueError(f"--tag-map 片段格式错误：{part}")
        tag_map[tag] = fields
    return tag_map

def first_nonblank(series: pd.Series, candidates: list[str]) -> tuple[str, str, int]:
    """
    在 candidates 指定的字段中，返回第一个非空值：
    - value_text: 文本
    - value_type: 命中的字段名（或 "EMPTY"）
    - priority_rank: 命中字段在 candidates 的下标（空值用大数 1e9）
    """
    for idx, col in enumerate(candidates):
        val = series.get(col, None)
        if not is_blank(val):
            return clean_str(val), col, idx
    return "", "EMPTY", 10**9  # 没命中

def ensure_cols(df: pd.DataFrame, cols: list[str]):
    missing = [c for c in cols if c not in df.columns]
    if missing:
        raise KeyError(f"源表缺少必要字段：{missing}")

# -------------------------
# 主流程
# -------------------------
def run(input_path: str, sheet, output_dir: str, tag_map_str: str):
    input_path = Path(input_path)
    output_dir = Path(output_dir) if output_dir else input_path.parent

    # 默认的 tag_map（只配 brand_name），可被 --tag-map 覆盖或增补
    default_tag_map = {
        "brand_name": ["store_name", "pop_name", "party_first_name"]
    }
    user_tag_map = parse_tag_map(tag_map_str)
    # 合并：用户优先覆盖同名标签，未覆盖的沿用默认
    tag_map = {**default_tag_map, **user_tag_map}

    # 读源数据
    read_kwargs = {"engine": "openpyxl"}
    if isinstance(sheet, int):
        read_kwargs["sheet_name"] = sheet
    elif isinstance(sheet, str) and sheet:
        read_kwargs["sheet_name"] = sheet

    df = pd.read_excel(input_path, **read_kwargs)

    # 基础字段校验（公共主键）
    ensure_cols(df, ["store_id", "pop_id"])
    # 取值候选字段校验（逐标签检查，缺少的字段不报错到死亡，只提示，并可输出 EMPTY）
    for tag_code, fields in tag_map.items():
        # 仅提示缺列，不强制中止
        miss = [c for c in fields if c not in df.columns]
        if miss:
            print(f"[WARN] tag_code={tag_code} 缺少候选字段：{miss}（对应行将输出 EMPTY）", file=sys.stderr)

    # 生成长表：对每个 tag_code 来一轮抽取
    records = []
    for idx, row in df.iterrows():
        base = {
            "store_id": row["store_id"],
            "pop_id": row["pop_id"],
        }
        for tag_code, fields in tag_map.items():
            value_text, value_type, priority_rank = first_nonblank(row, fields)
            records.append({
                **base,
                "tag_code": tag_code,
                "value_text": value_text,
                "value_type": value_type,
                "priority_rank": priority_rank,
                # date_ob 用东京时区当天日期
                "date_ob": datetime.now(ZoneInfo("Asia/Tokyo")).date().isoformat(),
                "_row_id": idx,  # 便于排查溯源
            })

    long_df = pd.DataFrame.from_records(records)

    # 主键去重策略：
    #   1) 先按 priority_rank 升序（优先级高者靠前）
    #   2) 再按 is_empty 升序（非空优先）
    #   3) 再按 _row_id 升序（先出现优先）
    long_df["is_empty"] = long_df["value_text"].apply(lambda x: 1 if is_blank(x) else 0)
    long_df = long_df.sort_values(
        by=["store_id", "pop_id", "tag_code", "priority_rank", "is_empty", "_row_id"],
        ascending=[True, True, True, True, True, True]
    )
    dedup_df = long_df.drop_duplicates(subset=["store_id", "pop_id", "tag_code"], keep="first")

    # 输出列顺序
    out_cols = ["store_id", "pop_id", "tag_code", "value_text", "value_type", "date_ob"]
    out_df = dedup_df[out_cols].copy()

    # 文件名
    ts = datetime.now(ZoneInfo("Asia/Tokyo")).strftime("%Y%m%d_%H%M%S")
    out_path = output_dir / f"tag_seed_{ts}.csv"

    # 写 CSV（utf-8-sig 便于 Excel 打开中文不乱码）
    out_df.to_csv(out_path, index=False, encoding="utf-8-sig")

    # 简要汇总打印
    total_rows = len(out_df)
    empty_rows = int((out_df["value_type"] == "EMPTY").sum())
    print(f"[DONE] 输出：{out_path}")
    print(f"[STAT] 总行数={total_rows}（去重后，主键=store_id+pop_id+tag_code）")
    print(f"[STAT] EMPTY 行数={empty_rows}（value_text 为空）")

# -------------------------
# CLI
# -------------------------
def build_parser():
    p = argparse.ArgumentParser(description="标签原始候选值导出（含主键去重）")
    p.add_argument("--input", required=True, help="输入 Excel 路径（.xlsx）")
    p.add_argument("--sheet", help="Sheet 名称或序号（不填默认第一个）")
    p.add_argument("--output-dir", default="", help="输出目录（默认与输入同目录）")
    p.add_argument(
        "--tag-map",
        default="",
        help=(
            "标签取值优先级映射，格式：tag=col1,col2;tag2=colA,colB 。"
            "示例：'brand_name=store_name,pop_name,party_first_name;brand_level=brand_level_std,brand_level_raw'"
        )
    )
    return p

def main():
    parser = build_parser()
    args = parser.parse_args()

    # 统一处理 sheet 参数类型（int/str）
    sheet = None
    if args.sheet:
        if re.fullmatch(r"\d+", str(args.sheet)):
            sheet = int(args.sheet)
        else:
            sheet = str(args.sheet)

    run(
        input_path=args.input,
        sheet=sheet,
        output_dir=args.output_dir,
        tag_map_str=args.tag_map
    )

if __name__ == "__main__":
    main()
```

### 怎么跑（当前你的诉求）

```bash
python tag_seed_export.py \
  --input "/Users/didi/Downloads/panth/tag_ct/total_list_full_58k.xlsx" \
  --sheet 0 \
  --tag-map "brand_name=store_name,pop_name,party_first_name"
```

* 产出：同目录下 `tag_seed_YYYYMMDD_HHMMSS.csv`
* 字段：`store_id,pop_id,tag_code,value_text,value_type,date_ob`
* 已按主键 `store_id+pop_id+tag_code` 去重。

### 快捷扩展更多标签（你说的“345 动态可加”）

只改一行命令里的 `--tag-map`：

```bash
# 例：再加两个标签 brand_level 与 city_name，分别定义取值优先级
python tag_seed_export.py \
  --input "/Users/didi/Downloads/panth/tag_ct/total_list_full_58k.xlsx" \
  --tag-map "brand_name=store_name,pop_name,party_first_name;brand_level=brand_level_std,brand_level_raw;city_name=city_std,city_raw"
```

* 每个 `tag_code` 都会产出一行候选（去重后保留优先级最高的非空值）。
* `value_type` 会标记命中的字段名，若都取不到则为 `EMPTY`（保留行，方便后续补齐/校验）。

### 备注

* 去重策略是“优先级高 > 非空 > 先出现”，确保稳定可复现。
* 日期 `date_ob` 使用东京时区当天，格式 `YYYY-MM-DD`。
* 如需过滤掉 `EMPTY` 行，后续可加开关（不在本次默认）。

如果没别的调整，你直接跑就行；后面要加指标统计、抽样校验、或把 `--tag-map` 换成 YAML 配置文件，我再给你补一版“监控 + 配置文件模式”的脚手架。
